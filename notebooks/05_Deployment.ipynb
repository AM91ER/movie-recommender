{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 5: Deployment\n",
    "## Movie Recommendation System - Streamlit App\n",
    "\n",
    "**Objectives:**\n",
    "1. Create a Streamlit web application\n",
    "2. Load trained models (SVD, Content-Based, Hybrid)\n",
    "3. Provide interactive movie recommendations\n",
    "4. Display movie information and explanations\n",
    "\n",
    "**Features:**\n",
    "- User selection (from existing users)\n",
    "- Multiple recommendation methods\n",
    "- Movie details and genres\n",
    "- Explanation of why movies are recommended"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Create Project Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "App directory: D:/Courses/DL INTERNSHIP/THIRD PROJECT/app\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define paths\n",
    "PROJECT_PATH = 'D:/Courses/DL INTERNSHIP/THIRD PROJECT'\n",
    "APP_PATH = f'{PROJECT_PATH}/app'\n",
    "\n",
    "# Create app directory\n",
    "os.makedirs(APP_PATH, exist_ok=True)\n",
    "\n",
    "print(f\"App directory: {APP_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Create Streamlit App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Streamlit app created: D:/Courses/DL INTERNSHIP/THIRD PROJECT/app/app.py\n"
     ]
    }
   ],
   "source": [
    "streamlit_app = '''\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from scipy.sparse import load_npz\n",
    "import os\n",
    "\n",
    "# ===========================================\n",
    "# CONFIGURATION\n",
    "# ===========================================\n",
    "st.set_page_config(\n",
    "    page_title=\"Movie Recommender\",\n",
    "    page_icon=\"ðŸŽ¬\",\n",
    "    layout=\"wide\"\n",
    ")\n",
    "\n",
    "# Paths\n",
    "BASE_PATH = os.path.dirname(os.path.abspath(__file__))\n",
    "DATA_PATH = os.path.join(BASE_PATH, \"..\", \"data\", \"ml_ready\")\n",
    "MODELS_PATH = os.path.join(BASE_PATH, \"..\", \"models\")\n",
    "\n",
    "# ===========================================\n",
    "# LOAD DATA AND MODELS (Cached)\n",
    "# ===========================================\n",
    "@st.cache_data\n",
    "def load_data():\n",
    "    \"\"\"Load preprocessed data.\"\"\"\n",
    "    # Load mappings\n",
    "    with open(os.path.join(DATA_PATH, \"mappings.pkl\"), \"rb\") as f:\n",
    "        mappings = pickle.load(f)\n",
    "    \n",
    "    # Load stats\n",
    "    with open(os.path.join(DATA_PATH, \"stats.pkl\"), \"rb\") as f:\n",
    "        stats = pickle.load(f)\n",
    "    \n",
    "    # Load movies\n",
    "    movies_df = pd.read_parquet(os.path.join(DATA_PATH, \"movies_train.parquet\"))\n",
    "    \n",
    "    # Load train data for user history\n",
    "    train_df = pd.read_parquet(os.path.join(DATA_PATH, \"train.parquet\"))\n",
    "    \n",
    "    # Load eval data\n",
    "    with open(os.path.join(DATA_PATH, \"eval_data.pkl\"), \"rb\") as f:\n",
    "        eval_data = pickle.load(f)\n",
    "    \n",
    "    return mappings, stats, movies_df, train_df, eval_data\n",
    "\n",
    "@st.cache_resource\n",
    "def load_models():\n",
    "    \"\"\"Load trained models.\"\"\"\n",
    "    # Load SVD model\n",
    "    with open(os.path.join(MODELS_PATH, \"svd_model.pkl\"), \"rb\") as f:\n",
    "        svd_model = pickle.load(f)\n",
    "    \n",
    "    # Load item similarity\n",
    "    item_similarity = np.load(os.path.join(MODELS_PATH, \"item_similarity.npy\"))\n",
    "    \n",
    "    # Load hybrid config\n",
    "    with open(os.path.join(MODELS_PATH, \"hybrid_config.pkl\"), \"rb\") as f:\n",
    "        hybrid_config = pickle.load(f)\n",
    "    \n",
    "    return svd_model, item_similarity, hybrid_config\n",
    "\n",
    "# ===========================================\n",
    "# RECOMMENDATION FUNCTIONS\n",
    "# ===========================================\n",
    "def get_user_history(user_idx, train_df, movies_df):\n",
    "    \"\"\"Get movies rated by a user.\"\"\"\n",
    "    user_ratings = train_df[train_df[\"user_idx\"] == user_idx].copy()\n",
    "    user_ratings = user_ratings.merge(movies_df[[\"item_idx\", \"title\", \"genres\"]], on=\"item_idx\")\n",
    "    user_ratings = user_ratings.sort_values(\"rating\", ascending=False)\n",
    "    return user_ratings[[\"title\", \"genres\", \"rating\"]]\n",
    "\n",
    "def predict_svd(user_idx, item_idx, svd_model):\n",
    "    \"\"\"Predict rating using SVD.\"\"\"\n",
    "    user_factors = svd_model[\"user_factors\"]\n",
    "    item_factors = svd_model[\"item_factors\"]\n",
    "    global_mean = svd_model[\"global_mean\"]\n",
    "    user_bias = svd_model[\"user_bias\"]\n",
    "    item_bias = svd_model[\"item_bias\"]\n",
    "    \n",
    "    user_idx = int(user_idx)\n",
    "    item_idx = int(item_idx)\n",
    "    \n",
    "    if user_idx < len(user_factors) and item_idx < len(item_factors):\n",
    "        latent_pred = np.dot(user_factors[user_idx], item_factors[item_idx])\n",
    "    else:\n",
    "        latent_pred = 0\n",
    "    \n",
    "    u_bias = user_bias.get(user_idx, 0)\n",
    "    i_bias = item_bias.get(item_idx, 0)\n",
    "    \n",
    "    pred = global_mean + u_bias + i_bias + latent_pred\n",
    "    return np.clip(pred, 0.5, 5.0)\n",
    "\n",
    "def get_svd_recommendations(user_idx, svd_model, user_positive, n_items, k=10):\n",
    "    \"\"\"Get SVD recommendations.\"\"\"\n",
    "    user_factors = svd_model[\"user_factors\"]\n",
    "    item_factors = svd_model[\"item_factors\"]\n",
    "    global_mean = svd_model[\"global_mean\"]\n",
    "    user_bias = svd_model[\"user_bias\"]\n",
    "    item_bias = svd_model[\"item_bias\"]\n",
    "    \n",
    "    user_idx = int(user_idx)\n",
    "    seen = user_positive.get(user_idx, set())\n",
    "    \n",
    "    # Compute predictions for all items\n",
    "    if user_idx < len(user_factors):\n",
    "        preds = np.dot(user_factors[user_idx], item_factors.T)\n",
    "    else:\n",
    "        preds = np.zeros(n_items)\n",
    "    \n",
    "    # Add biases\n",
    "    preds += global_mean\n",
    "    preds += user_bias.get(user_idx, 0)\n",
    "    for i in range(len(preds)):\n",
    "        preds[i] += item_bias.get(i, 0)\n",
    "    \n",
    "    # Mask seen items\n",
    "    for item in seen:\n",
    "        if item < len(preds):\n",
    "            preds[item] = -np.inf\n",
    "    \n",
    "    # Get top-k\n",
    "    top_k = np.argsort(preds)[-k:][::-1]\n",
    "    scores = preds[top_k]\n",
    "    \n",
    "    return list(zip(top_k.tolist(), scores.tolist()))\n",
    "\n",
    "def get_content_recommendations(user_idx, user_positive, item_similarity, \n",
    "                                 user_item_ratings, relevance_threshold=4.0, k=10):\n",
    "    \"\"\"Get content-based recommendations.\"\"\"\n",
    "    user_idx = int(user_idx)\n",
    "    seen = user_positive.get(user_idx, set())\n",
    "    n_items = item_similarity.shape[0]\n",
    "    \n",
    "    if len(seen) == 0:\n",
    "        return []\n",
    "    \n",
    "    # Get liked items\n",
    "    liked_items = []\n",
    "    for item_idx in seen:\n",
    "        if item_idx in user_item_ratings.get(user_idx, {}):\n",
    "            if user_item_ratings[user_idx][item_idx] >= relevance_threshold:\n",
    "                liked_items.append(item_idx)\n",
    "    \n",
    "    if len(liked_items) == 0:\n",
    "        liked_items = list(seen)[:10]\n",
    "    \n",
    "    # Compute scores\n",
    "    scores = np.zeros(n_items)\n",
    "    for liked in liked_items:\n",
    "        if liked < n_items:\n",
    "            scores += item_similarity[liked]\n",
    "    scores /= max(len(liked_items), 1)\n",
    "    \n",
    "    # Mask seen\n",
    "    for item in seen:\n",
    "        if item < n_items:\n",
    "            scores[item] = -np.inf\n",
    "    \n",
    "    # Get top-k\n",
    "    top_k = np.argsort(scores)[-k:][::-1]\n",
    "    top_scores = scores[top_k]\n",
    "    \n",
    "    return list(zip(top_k.tolist(), top_scores.tolist()))\n",
    "\n",
    "def get_hybrid_recommendations(user_idx, svd_model, user_positive, item_similarity,\n",
    "                                user_item_ratings, n_items, alpha=0.5, k=10):\n",
    "    \"\"\"Get hybrid recommendations.\"\"\"\n",
    "    user_idx = int(user_idx)\n",
    "    seen = user_positive.get(user_idx, set())\n",
    "    n_items_local = min(n_items, item_similarity.shape[0])\n",
    "    \n",
    "    # SVD scores\n",
    "    user_factors = svd_model[\"user_factors\"]\n",
    "    item_factors = svd_model[\"item_factors\"]\n",
    "    global_mean = svd_model[\"global_mean\"]\n",
    "    user_bias_dict = svd_model[\"user_bias\"]\n",
    "    item_bias_dict = svd_model[\"item_bias\"]\n",
    "    \n",
    "    if user_idx < len(user_factors):\n",
    "        svd_preds = np.dot(user_factors[user_idx], item_factors[:n_items_local].T)\n",
    "    else:\n",
    "        svd_preds = np.zeros(n_items_local)\n",
    "    \n",
    "    svd_preds += global_mean + user_bias_dict.get(user_idx, 0)\n",
    "    for i in range(n_items_local):\n",
    "        svd_preds[i] += item_bias_dict.get(i, 0)\n",
    "    \n",
    "    svd_scores = (svd_preds - 0.5) / 4.5  # Normalize to 0-1\n",
    "    \n",
    "    # Content-based scores\n",
    "    liked_items = []\n",
    "    for item_idx in seen:\n",
    "        if item_idx in user_item_ratings.get(user_idx, {}):\n",
    "            if user_item_ratings[user_idx][item_idx] >= 4.0:\n",
    "                liked_items.append(item_idx)\n",
    "    \n",
    "    if len(liked_items) == 0:\n",
    "        liked_items = [item for item in seen if item < n_items_local][:10]\n",
    "    \n",
    "    cb_scores = np.zeros(n_items_local)\n",
    "    if len(liked_items) > 0:\n",
    "        for liked in liked_items:\n",
    "            if liked < n_items_local:\n",
    "                cb_scores += item_similarity[liked, :n_items_local]\n",
    "        cb_scores /= len(liked_items)\n",
    "    \n",
    "    # Combine\n",
    "    hybrid_scores = alpha * svd_scores + (1 - alpha) * cb_scores\n",
    "    \n",
    "    # Mask seen\n",
    "    for item in seen:\n",
    "        if item < n_items_local:\n",
    "            hybrid_scores[item] = -np.inf\n",
    "    \n",
    "    # Get top-k\n",
    "    top_k = np.argsort(hybrid_scores)[-k:][::-1]\n",
    "    top_scores = hybrid_scores[top_k]\n",
    "    \n",
    "    return list(zip(top_k.tolist(), top_scores.tolist()))\n",
    "\n",
    "def get_popularity_recommendations(user_positive, item_popularity, user_idx, k=10):\n",
    "    \"\"\"Get popularity-based recommendations.\"\"\"\n",
    "    user_idx = int(user_idx)\n",
    "    seen = user_positive.get(user_idx, set())\n",
    "    \n",
    "    # Sort by popularity\n",
    "    sorted_items = sorted(item_popularity.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    recs = []\n",
    "    for item_idx, pop in sorted_items:\n",
    "        if item_idx not in seen:\n",
    "            recs.append((item_idx, pop))\n",
    "            if len(recs) >= k:\n",
    "                break\n",
    "    \n",
    "    return recs\n",
    "\n",
    "# ===========================================\n",
    "# MAIN APP\n",
    "# ===========================================\n",
    "def main():\n",
    "    st.title(\"ðŸŽ¬ Movie Recommendation System\")\n",
    "    st.markdown(\"*Powered by Matrix Factorization + Content-Based Filtering*\")\n",
    "    \n",
    "    # Load data and models\n",
    "    with st.spinner(\"Loading data and models...\"):\n",
    "        mappings, stats, movies_df, train_df, eval_data = load_data()\n",
    "        svd_model, item_similarity, hybrid_config = load_models()\n",
    "    \n",
    "    n_users = mappings[\"n_users\"]\n",
    "    n_items = mappings[\"n_items\"]\n",
    "    user_positive = eval_data[\"user_positive_items\"]\n",
    "    item_popularity = stats[\"item_popularity\"]\n",
    "    \n",
    "    # Build user-item ratings lookup\n",
    "    user_item_ratings = {}\n",
    "    for _, row in train_df.iterrows():\n",
    "        u = int(row[\"user_idx\"])\n",
    "        i = int(row[\"item_idx\"])\n",
    "        r = row[\"rating\"]\n",
    "        if u not in user_item_ratings:\n",
    "            user_item_ratings[u] = {}\n",
    "        user_item_ratings[u][i] = r\n",
    "    \n",
    "    # Sidebar\n",
    "    st.sidebar.header(\"âš™ï¸ Settings\")\n",
    "    \n",
    "    # User selection\n",
    "    user_idx = st.sidebar.number_input(\n",
    "        \"User ID\", \n",
    "        min_value=0, \n",
    "        max_value=n_users-1, \n",
    "        value=0,\n",
    "        help=\"Select a user ID to get personalized recommendations\"\n",
    "    )\n",
    "    \n",
    "    # Recommendation method\n",
    "    method = st.sidebar.selectbox(\n",
    "        \"Recommendation Method\",\n",
    "        [\"Hybrid (SVD + Content)\", \"SVD (Collaborative)\", \"Content-Based (Genres)\", \"Popularity\"]\n",
    "    )\n",
    "    \n",
    "    # Number of recommendations\n",
    "    n_recs = st.sidebar.slider(\"Number of Recommendations\", 5, 20, 10)\n",
    "    \n",
    "    # Alpha for hybrid\n",
    "    if method == \"Hybrid (SVD + Content)\":\n",
    "        alpha = st.sidebar.slider(\n",
    "            \"Hybrid Alpha (SVD weight)\", \n",
    "            0.0, 1.0, \n",
    "            hybrid_config[\"best_alpha\"],\n",
    "            help=\"0 = Pure Content-Based, 1 = Pure SVD\"\n",
    "        )\n",
    "    else:\n",
    "        alpha = 0.5\n",
    "    \n",
    "    # Main content\n",
    "    col1, col2 = st.columns([1, 2])\n",
    "    \n",
    "    with col1:\n",
    "        st.subheader(f\"ðŸ‘¤ User {user_idx} History\")\n",
    "        user_history = get_user_history(user_idx, train_df, movies_df)\n",
    "        if len(user_history) > 0:\n",
    "            st.write(f\"Movies rated: {len(user_history)}\")\n",
    "            st.dataframe(\n",
    "                user_history.head(10),\n",
    "                use_container_width=True,\n",
    "                hide_index=True\n",
    "            )\n",
    "        else:\n",
    "            st.warning(\"No rating history found for this user.\")\n",
    "    \n",
    "    with col2:\n",
    "        st.subheader(f\"ðŸŽ¯ Recommendations ({method})\")\n",
    "        \n",
    "        # Get recommendations\n",
    "        if method == \"Hybrid (SVD + Content)\":\n",
    "            recs = get_hybrid_recommendations(\n",
    "                user_idx, svd_model, user_positive, item_similarity,\n",
    "                user_item_ratings, n_items, alpha=alpha, k=n_recs\n",
    "            )\n",
    "        elif method == \"SVD (Collaborative)\":\n",
    "            recs = get_svd_recommendations(\n",
    "                user_idx, svd_model, user_positive, n_items, k=n_recs\n",
    "            )\n",
    "        elif method == \"Content-Based (Genres)\":\n",
    "            recs = get_content_recommendations(\n",
    "                user_idx, user_positive, item_similarity,\n",
    "                user_item_ratings, k=n_recs\n",
    "            )\n",
    "        else:  # Popularity\n",
    "            recs = get_popularity_recommendations(\n",
    "                user_positive, item_popularity, user_idx, k=n_recs\n",
    "            )\n",
    "        \n",
    "        # Display recommendations\n",
    "        if len(recs) > 0:\n",
    "            rec_data = []\n",
    "            for item_idx, score in recs:\n",
    "                movie_info = movies_df[movies_df[\"item_idx\"] == item_idx]\n",
    "                if len(movie_info) > 0:\n",
    "                    rec_data.append({\n",
    "                        \"Title\": movie_info[\"title\"].values[0],\n",
    "                        \"Genres\": movie_info[\"genres\"].values[0],\n",
    "                        \"Score\": f\"{score:.3f}\" if method != \"Popularity\" else f\"{int(score):,} ratings\"\n",
    "                    })\n",
    "            \n",
    "            rec_df = pd.DataFrame(rec_data)\n",
    "            st.dataframe(rec_df, use_container_width=True, hide_index=True)\n",
    "        else:\n",
    "            st.warning(\"No recommendations available.\")\n",
    "    \n",
    "    # Footer\n",
    "    st.markdown(\"---\")\n",
    "    st.markdown(\n",
    "        \"\"\"\n",
    "        **About this system:**\n",
    "        - **SVD**: Learns latent factors from user-item interactions\n",
    "        - **Content-Based**: Recommends movies with similar genres to what you liked\n",
    "        - **Hybrid**: Combines both approaches for better recommendations\n",
    "        - **Popularity**: Recommends most popular movies you haven\\'t seen\n",
    "        \n",
    "        Built with MovieLens 32M dataset (30% sample) | SVD RMSE: 0.87\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "'''\n",
    "\n",
    "# Write the Streamlit app\n",
    "with open(f'{APP_PATH}/app.py', 'w', encoding='utf-8') as f:\n",
    "    f.write(streamlit_app)\n",
    "\n",
    "print(f\"Streamlit app created: {APP_PATH}/app.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Create Requirements File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirements file created: D:/Courses/DL INTERNSHIP/THIRD PROJECT/app/requirements.txt\n",
      "\n",
      "Contents:\n",
      "streamlit>=1.28.0\n",
      "pandas>=2.0.0\n",
      "numpy>=1.24.0\n",
      "scipy>=1.10.0\n",
      "pyarrow>=12.0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "requirements = '''streamlit>=1.28.0\n",
    "pandas>=2.0.0\n",
    "numpy>=1.24.0\n",
    "scipy>=1.10.0\n",
    "pyarrow>=12.0.0\n",
    "'''\n",
    "\n",
    "with open(f'{APP_PATH}/requirements.txt', 'w') as f:\n",
    "    f.write(requirements)\n",
    "\n",
    "print(f\"Requirements file created: {APP_PATH}/requirements.txt\")\n",
    "print(\"\\nContents:\")\n",
    "print(requirements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Create README"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README created: D:/Courses/DL INTERNSHIP/THIRD PROJECT/app/README.md\n"
     ]
    }
   ],
   "source": [
    "readme = '''# ðŸŽ¬ Movie Recommendation System\n",
    "\n",
    "A hybrid movie recommendation system built with Matrix Factorization (SVD) and Content-Based Filtering.\n",
    "\n",
    "## Features\n",
    "\n",
    "- **SVD (Collaborative Filtering)**: Learns user preferences from rating patterns\n",
    "- **Content-Based Filtering**: Recommends movies with similar genres\n",
    "- **Hybrid Model**: Combines both approaches for better recommendations\n",
    "- **Popularity Baseline**: Recommends trending movies\n",
    "\n",
    "## Dataset\n",
    "\n",
    "- MovieLens 32M Dataset (30% sample)\n",
    "- ~9.6 million ratings\n",
    "- ~60,000 users\n",
    "- ~27,500 movies\n",
    "- 19 genres\n",
    "\n",
    "## Model Performance\n",
    "\n",
    "| Model | RMSE | NDCG@10 |\n",
    "|-------|------|--------|\n",
    "| Global Mean | 1.05 | - |\n",
    "| User-Item Bias | 0.92 | - |\n",
    "| SVD | **0.87** | 0.015 |\n",
    "| Hybrid | - | **0.040** |\n",
    "\n",
    "## Installation\n",
    "\n",
    "```bash\n",
    "# Install dependencies\n",
    "pip install -r requirements.txt\n",
    "\n",
    "# Run the app\n",
    "streamlit run app.py\n",
    "```\n",
    "\n",
    "## Project Structure\n",
    "\n",
    "```\n",
    "THIRD PROJECT/\n",
    "â”œâ”€â”€ app/\n",
    "â”‚   â”œâ”€â”€ app.py              # Streamlit application\n",
    "â”‚   â”œâ”€â”€ requirements.txt    # Python dependencies\n",
    "â”‚   â””â”€â”€ README.md           # This file\n",
    "â”œâ”€â”€ data/\n",
    "â”‚   â”œâ”€â”€ processed/          # Cleaned data\n",
    "â”‚   â””â”€â”€ ml_ready/           # ML-ready data\n",
    "â”œâ”€â”€ models/\n",
    "â”‚   â”œâ”€â”€ svd_model.pkl       # Trained SVD model\n",
    "â”‚   â”œâ”€â”€ item_similarity.npy # Genre similarity matrix\n",
    "â”‚   â””â”€â”€ hybrid_config.pkl   # Hybrid model config\n",
    "â””â”€â”€ Notebooks/\n",
    "    â”œâ”€â”€ 01_Data_Understanding_Cleaning_Sampling.ipynb\n",
    "    â”œâ”€â”€ 02_EDA.ipynb\n",
    "    â”œâ”€â”€ 03_ML_Preprocessing.ipynb\n",
    "    â””â”€â”€ 04_Model_Training.ipynb\n",
    "```\n",
    "\n",
    "## Usage\n",
    "\n",
    "1. Select a User ID from the sidebar\n",
    "2. Choose a recommendation method\n",
    "3. Adjust the number of recommendations\n",
    "4. For Hybrid mode, adjust the alpha slider:\n",
    "   - Î± = 1.0: Pure SVD\n",
    "   - Î± = 0.0: Pure Content-Based\n",
    "   - Î± = 0.5: Equal weight\n",
    "\n",
    "## Technologies\n",
    "\n",
    "- Python 3.12\n",
    "- Streamlit (Web UI)\n",
    "- NumPy/SciPy (Matrix operations)\n",
    "- Pandas (Data handling)\n",
    "- Scikit-learn (Similarity computation)\n",
    "\n",
    "## Author\n",
    "\n",
    "Built as part of Deep Learning Internship - Third Project\n",
    "'''\n",
    "\n",
    "with open(f'{APP_PATH}/README.md', 'w', encoding='utf-8') as f:\n",
    "    f.write(readme)\n",
    "\n",
    "print(f\"README created: {APP_PATH}/README.md\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Create Run Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run script created: D:/Courses/DL INTERNSHIP/THIRD PROJECT/app/run.bat\n"
     ]
    }
   ],
   "source": [
    "# Windows batch file\n",
    "run_bat = '''@echo off\n",
    "echo Starting Movie Recommendation System...\n",
    "echo.\n",
    "echo Make sure you have installed the requirements:\n",
    "echo   pip install -r requirements.txt\n",
    "echo.\n",
    "streamlit run app.py\n",
    "pause\n",
    "'''\n",
    "\n",
    "with open(f'{APP_PATH}/run.bat', 'w') as f:\n",
    "    f.write(run_bat)\n",
    "\n",
    "print(f\"Run script created: {APP_PATH}/run.bat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Verify All Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "APP FILES CREATED\n",
      "============================================================\n",
      "  app.py: 12.4 KB\n",
      "  README.md: 2.1 KB\n",
      "  requirements.txt: 0.1 KB\n",
      "  run.bat: 0.2 KB\n",
      "\n",
      "============================================================\n",
      "TO RUN THE APP\n",
      "============================================================\n",
      "  \n",
      "1. Open a terminal/command prompt\n",
      "2. Navigate to: D:/Courses/DL INTERNSHIP/THIRD PROJECT/app\n",
      "3. Install requirements:\n",
      "   pip install -r requirements.txt\n",
      "4. Run the app:\n",
      "   streamlit run app.py\n",
      "5. Open browser at: http://localhost:8501\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"APP FILES CREATED\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for f in os.listdir(APP_PATH):\n",
    "    filepath = os.path.join(APP_PATH, f)\n",
    "    size = os.path.getsize(filepath) / 1024\n",
    "    print(f\"  {f}: {size:.1f} KB\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TO RUN THE APP\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\"\"  \n",
    "1. Open a terminal/command prompt\n",
    "2. Navigate to: {APP_PATH}\n",
    "3. Install requirements:\n",
    "   pip install -r requirements.txt\n",
    "4. Run the app:\n",
    "   streamlit run app.py\n",
    "5. Open browser at: http://localhost:8501\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Phase 5 Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "PHASE 5 SUMMARY: DEPLOYMENT\n",
      "======================================================================\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "STREAMLIT APP FEATURES\n",
      "----------------------------------------------------------------------\n",
      "  âœ“ User selection (60,284 users available)\n",
      "  âœ“ Multiple recommendation methods:\n",
      "    - Hybrid (SVD + Content-Based)\n",
      "    - SVD (Collaborative Filtering)\n",
      "    - Content-Based (Genre Similarity)\n",
      "    - Popularity Baseline\n",
      "  âœ“ Adjustable parameters (alpha, n_recs)\n",
      "  âœ“ User rating history display\n",
      "  âœ“ Movie details (title, genres, score)\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "FILES CREATED\n",
      "----------------------------------------------------------------------\n",
      "  Location: D:/Courses/DL INTERNSHIP/THIRD PROJECT/app\n",
      "  - app.py: Main Streamlit application\n",
      "  - requirements.txt: Python dependencies\n",
      "  - README.md: Documentation\n",
      "  - run.bat: Windows launch script\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "REQUIRED MODEL FILES\n",
      "----------------------------------------------------------------------\n",
      "  From models/ folder:\n",
      "  - svd_model.pkl (17.75 MB)\n",
      "  - item_similarity.npy (2884.45 MB)\n",
      "  - hybrid_config.pkl\n",
      "  \n",
      "  From data/ml_ready/ folder:\n",
      "  - mappings.pkl\n",
      "  - stats.pkl\n",
      "  - movies_train.parquet\n",
      "  - train.parquet\n",
      "  - eval_data.pkl\n",
      "\n",
      "======================================================================\n",
      "PROJECT COMPLETE!\n",
      "======================================================================\n",
      "\n",
      "Congratulations! You have completed the Movie Recommendation System project.\n",
      "\n",
      "Summary of all phases:\n",
      "  Phase 1: Data Understanding, Cleaning & Sampling\n",
      "  Phase 2: Exploratory Data Analysis (EDA)\n",
      "  Phase 3: ML Preprocessing\n",
      "  Phase 4: Model Training\n",
      "  Phase 5: Deployment (Streamlit App)\n",
      "\n",
      "To run the app:\n",
      "  cd D:/Courses/DL INTERNSHIP/THIRD PROJECT/app\n",
      "  streamlit run app.py\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"PHASE 5 SUMMARY: DEPLOYMENT\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"STREAMLIT APP FEATURES\")\n",
    "print(\"-\" * 70)\n",
    "print(\"  âœ“ User selection (60,284 users available)\")\n",
    "print(\"  âœ“ Multiple recommendation methods:\")\n",
    "print(\"    - Hybrid (SVD + Content-Based)\")\n",
    "print(\"    - SVD (Collaborative Filtering)\")\n",
    "print(\"    - Content-Based (Genre Similarity)\")\n",
    "print(\"    - Popularity Baseline\")\n",
    "print(\"  âœ“ Adjustable parameters (alpha, n_recs)\")\n",
    "print(\"  âœ“ User rating history display\")\n",
    "print(\"  âœ“ Movie details (title, genres, score)\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"FILES CREATED\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"  Location: {APP_PATH}\")\n",
    "print(\"  - app.py: Main Streamlit application\")\n",
    "print(\"  - requirements.txt: Python dependencies\")\n",
    "print(\"  - README.md: Documentation\")\n",
    "print(\"  - run.bat: Windows launch script\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"REQUIRED MODEL FILES\")\n",
    "print(\"-\" * 70)\n",
    "print(\"  From models/ folder:\")\n",
    "print(\"  - svd_model.pkl (17.75 MB)\")\n",
    "print(\"  - item_similarity.npy (2884.45 MB)\")\n",
    "print(\"  - hybrid_config.pkl\")\n",
    "print(\"  \")\n",
    "print(\"  From data/ml_ready/ folder:\")\n",
    "print(\"  - mappings.pkl\")\n",
    "print(\"  - stats.pkl\")\n",
    "print(\"  - movies_train.parquet\")\n",
    "print(\"  - train.parquet\")\n",
    "print(\"  - eval_data.pkl\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PROJECT COMPLETE!\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\"\"\n",
    "Congratulations! You have completed the Movie Recommendation System project.\n",
    "\n",
    "Summary of all phases:\n",
    "  Phase 1: Data Understanding, Cleaning & Sampling\n",
    "  Phase 2: Exploratory Data Analysis (EDA)\n",
    "  Phase 3: ML Preprocessing\n",
    "  Phase 4: Model Training\n",
    "  Phase 5: Deployment (Streamlit App)\n",
    "\n",
    "To run the app:\n",
    "  cd {}\n",
    "  streamlit run app.py\n",
    "\"\"\".format(APP_PATH))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
